## FFmpeg

### 1. 视频基本知识

I 帧：关键帧，采用帧内压缩技术

P 帧：向前参考帧，压缩时只参考前一个帧，属于帧间压缩技术

B 帧：双向参考帧，压缩时即参考前一帧也参考后一帧，属于帧间压缩技术

一般实时互动都不会使用 B 帧

GOF(group of frame): 一组帧，可以将一段时间内画面变化不大的所有帧划为一组帧

SPS 与 PPS（这两种都划为 I 帧）：

- SPS(Sequence Parameter Set):

  序列参数集，存放帧数、参考帧数目、解码图像尺寸、帧场编码模式选择标识等。

- PPS(Picture Parameter Set):

  图像参数集，存放熵编码模式选择标识、片组数目、初始量化参数和去方块滤波系统数调整标识等

视频花屏 / 卡顿原因：

1、如果 GOP 分组中的 P 帧丢失会造成解码端的图像发生错误（于是形成了花屏）。

2、为了避免花屏问题的发生，一般如果发现 P 帧或者 I 帧丢失，就不显示本 GOP 内的所有帧，直到下一个 I 帧来后重新刷新图像（因为丢了一组数据，所以形成了卡顿）

H264 压缩技术

1. 帧内预测压缩，解决的是空域数据冗余问题（将一幅图里的人眼不是很敏感的色彩、光亮等数据剔除）
2. 帧间预测压缩，解决的是时域数据冗余问题（将一组图里面连续的重复性高的帧剔除）
3. 整数离散余弦变换 (DCT)，将空间上的相关性变为频域上无关的数据然后进行量化
4. CABAC 压缩，也叫上下文适应无损压缩

宏块的划分与分组：

H264 宏块划分与子块划分：宏块里面可以再包含很多子块

子块划分：

帧分组 (一组连续的图片，一幅图片为一帧)

- 帧间预测:

  解决时间数据冗余，比较相邻两帧不同给出运动矢量 + 残差值

- 帧内预测:

  解决空间数据冗余，每一个宏块有一个预测模式，然后讲预测后的图像与原图比较算差值，最后存储预测模式和差值即可。帧内压缩是针对于 I 帧的

H264 编码分层：

1、NAL 层（Network Abstraction Layer）, 视频数据网络抽象层。

2、VCL 层（Video Coding Layer），视频数据编码层，对原始数据进行压缩

码流基本概念：

1、SODB（String Of Data Bits）, 原始数据比特流，长度不一定是 8 的倍数，它是由 VCL 层产生的。

2、RBSP（Raw Byte Sequence Payload,SODB+trailing bits），算法是在 SODB 最后一位补 1，不按字节对齐则补 0。

3、EBSP(Encapsulate Byte Sequence Payload)，需到两个连续的 0x00 就增加一个 0x03。

4、NALU，NAL Header(1B)+EBSP

一个 H264 帧最少要有一个切片 (NAL Unit)

切片与宏块的关系：

- 每个切片都包括切片头和切片数据，
- 每个切片数据又包括了很多宏块，
- 每个宏块又包括了宏块的类型、宏块的预测、编码的残渣数据等

NAL类型介绍

- 单一类型：一个 RTP 包只包含一个NALU
- 组合类型：一个 RTP 包含多个 NALU，类型是24-27
- 分片类型：一个 NALU 单元分成多个 RTP 包，类型是 28 和 29

P 帧 B 帧很多都是单一类型。

SPS 和 PPS 这两个 NAL 单元一般放在同一个 RTP 包里头

YUV 是电视系统所采用的一种颜色编码方法，Y 表示明亮度，也就是灰阶值，他是基础信号，U 和 V 表示的则是色度，UV 的作用是描述像色彩及饱和度，他们用于指定像素的颜色。

YUV 常见格式：YUV4:2:0、YUV4:2:2、YUV4:4:4

RGB8:8:8

YUV 存储格式：

- UV 混存则为 packed(打包存储)，
- UV 分开存则为 planar(平面存储)

FFmpeg 操作流数据的基本步骤：

解复用 —> 获取流 —> 读取数据包 —> 释放资源

SDL 事件基本原理

- SDL 将所有的事件都存放在一个队列中
- 所有对事件的操作，其实就是队列的操作

SDL 事件种类：

- SDL_WindowEvent：窗口事件
- SDL_KeyboardEvent：键盘事件
- SDL_MouseMotionEvent：鼠标事件
- 自定义事件







